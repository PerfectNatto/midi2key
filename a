#include <iostream>
#include <vector>
#include <cstdlib>
#include <cstdio>
#include <inttypes.h>

#include <gflags/gflags.h>

#include <executorch/extension/data_loader/file_data_loader.h>
#include <executorch/extension/evalue_util/print_evalue.h>
#include <executorch/extension/runner_util/inputs.h>
#include <executorch/runtime/core/event_tracer.h>
#include <executorch/runtime/core/memory_allocator.h>
#include <executorch/runtime/executor/method.h>
#include <executorch/runtime/executor/program.h>
#include <executorch/runtime/platform/log.h>
#include <executorch/runtime/platform/platform.h>
#include <executorch/runtime/platform/runtime.h>
#ifdef ET_EVENT_TRACER_ENABLED
#include <executorch/devtools/etdump/etdump_flatcc.h>
#endif // ET_EVENT_TRACER_ENABLED

#if defined(ET_USE_THREADPOOL)
#include <executorch/extension/threadpool/cpuinfo_utils.h>
#include <executorch/extension/threadpool/threadpool.h>
#endif

// -------------------------------------------------------
// gflags
// -------------------------------------------------------
DEFINE_string(model_path, "model.pte", "Model serialized in flatbuffer format.");
DEFINE_uint32(num_executions, 1, "Number of times to run the model.");
#ifdef ET_EVENT_TRACER_ENABLED
DEFINE_string(etdump_path, "model.etdump", "Write ETDump data to this path.");
#endif
DEFINE_int32(cpu_threads, -1, "Number of CPU threads for inference. -1 = heuristic");

// -------------------------------------------------------
// aliases
// -------------------------------------------------------
using executorch::extension::FileDataLoader;
using executorch::runtime::Error;
using executorch::runtime::EValue;
using executorch::runtime::EventTracer;
using executorch::runtime::HierarchicalAllocator;
using executorch::runtime::MemoryAllocator;
using executorch::runtime::MemoryManager;
using executorch::runtime::Method;
using executorch::runtime::MethodMeta;
using executorch::runtime::Program;
using executorch::runtime::Result;
using executorch::runtime::Span;

// -------------------------------------------------------
// ETDump helper
// -------------------------------------------------------
class EventTraceManager {
 public:
  EventTraceManager() {
#ifdef ET_EVENT_TRACER_ENABLED
    tracer_ = std::make_shared<executorch::etdump::ETDumpGen>();
#endif
  }
  EventTracer* get() const { return tracer_.get(); }

  Error dump_to_file() const {
#ifdef ET_EVENT_TRACER_ENABLED
    const char* path = FLAGS_etdump_path.c_str();
    std::unique_ptr<FILE, decltype(&fclose)> fp{fopen(path, "wb"), fclose};
    if (!fp) {
      ET_LOG(Error, "Failed to open ETDump file %s", path);
      return Error::AccessFailed;
    }
    auto* gen = static_cast<executorch::etdump::ETDumpGen*>(tracer_.get());
    executorch::etdump::ETDumpResult r = gen->get_etdump_data();
    if (r.buf && r.size > 0) {
      fwrite(r.buf, 1, r.size, fp.get());
      free(r.buf);
      ET_LOG(Info, "ETDump written to %s", path);
      return Error::Ok;
    }
    return Error::NotFound;
#else
    return Error::NotSupported;
#endif
  }

 private:
  std::shared_ptr<EventTracer> tracer_{nullptr};
};

int main(int argc, char** argv) {
  executorch::runtime::runtime_init();

  // CLI
  gflags::ParseCommandLineFlags(&argc, &argv, true);
  if (argc != 1) {
    std::string msg = "Extra command-line args:";
    for (int i = 1; i < argc; ++i) msg += " " + std::string(argv[i]);
    ET_LOG(Error, "%s", msg.c_str());
    return 1;
  }

  // Threadâ€‘pool (optional)
#if defined(ET_USE_THREADPOOL)
  uint32_t threads = (FLAGS_cpu_threads == -1)
      ? ::executorch::extension::cpuinfo::get_num_performant_cores()
      : static_cast<uint32_t>(FLAGS_cpu_threads);
  ET_LOG(Info, "Resetting threadpool with %u threads", threads);
  if (threads > 0) {
    ::executorch::extension::threadpool::get_threadpool()->_unsafe_reset_threadpool(threads);
  }
#endif

  // Load model
  Result<FileDataLoader> loader = FileDataLoader::from(FLAGS_model_path.c_str());
  ET_CHECK_MSG(loader.ok(), "FileDataLoader::from() failed: 0x%08" PRIx32, (uint32_t)loader.error());

  Result<Program> program = Program::load(&loader.get());
  ET_CHECK_MSG(program.ok(), "Failed to parse model file %s", FLAGS_model_path.c_str());
  ET_LOG(Info, "Model file %s loaded", FLAGS_model_path.c_str());

  // First method
  const char* method_name = nullptr;
  {
    auto r = program->get_method_name(0);
    ET_CHECK_MSG(r.ok(), "Program has no methods");
    method_name = *r;
  }
  ET_LOG(Info, "Using method %s", method_name);

  Result<MethodMeta> meta = program->method_meta(method_name);
  ET_CHECK_MSG(meta.ok(), "Failed to get method_meta for %s: 0x%08" PRIx32, method_name, (uint32_t)meta.error());

  // ------------------------------------------------------------------------------------
  // Memory allocators
  //   * Method allocator  : malloc-based (dynamic), avoids guessing pool size.
  //   * Temp allocator    : malloc-based (dynamic).
  //   * Planned memory    : hierarchy of arenas sized exactly per MethodMeta.
  // ------------------------------------------------------------------------------------
  executorch::extension::MallocMemoryAllocator method_alloc;
  executorch::extension::MallocMemoryAllocator temp_alloc;

  size_t n_buf = meta->num_memory_planned_buffers();
  std::vector<std::vector<uint8_t>> planned_buf(n_buf);
  std::vector<Span<uint8_t>>        planned_spans(n_buf);
  for (size_t i = 0; i < n_buf; ++i) {
    size_t sz = static_cast<size_t>(meta->memory_planned_buffer_size(i).get());
    ET_LOG(Info, "Planned buffer %zu : %zu bytes", i, sz);
    planned_buf[i].resize(sz);
    planned_spans[i] = {planned_buf[i].data(), sz};
  }
  HierarchicalAllocator planned_mem({planned_spans.data(), planned_spans.size()});
  MemoryManager mem_mgr(&method_alloc, &planned_mem, &temp_alloc);(&method_alloc, &planned_mem, &temp_alloc);

  // Load method
  EventTraceManager trace_mgr;
  Result<Method> method = program->load_method(method_name, &mem_mgr, trace_mgr.get());
  ET_CHECK_MSG(method.ok(), "load_method(%s) failed: 0x%08" PRIx32, method_name, (uint32_t)method.error());
  ET_LOG(Info, "Method loaded");

  // Execute
  et_timestamp_t exec_time_ticks = 0;
  for (uint32_t i = 0; i < FLAGS_num_executions; ++i) {
    ET_LOG(Debug, "Preparing inputs (%u/%u)", i + 1, FLAGS_num_executions);
    auto inputs = executorch::extension::prepare_input_tensors(*method);
    ET_CHECK_MSG(inputs.ok(), "prepare_input_tensors failed: 0x%08" PRIx32, (uint32_t)inputs.error());

    et_timestamp_t t0 = executorch::runtime::pal_current_ticks();
    Error st = method->execute();
    et_timestamp_t t1 = executorch::runtime::pal_current_ticks();
    exec_time_ticks += t1 - t0;
    ET_CHECK_MSG(st == Error::Ok, "Execution failed with status 0x%08" PRIx32, (uint32_t)st);
  }

  constexpr double NS_PER_MS = 1'000'000.0;
  auto ratio = et_pal_ticks_to_ns_multiplier();
  double ms = static_cast<double>(exec_time_ticks) * ratio.numerator / ratio.denominator / NS_PER_MS;
  ET_LOG(Info, "Executed %u time(s) in %.3f ms", FLAGS_num_executions, ms);

  // Outputs
  std::vector<EValue> outputs(method->outputs_size());
  ET_CHECK(method->get_outputs(outputs.data(), outputs.size()) == Error::Ok);
  std::cout << executorch::extension::evalue_edge_items(100);
  for (size_t i = 0; i < outputs.size(); ++i) {
    std::cout << "Output " << i << ": " << outputs[i] << std::endl;
  }

  // ETDump
  if (trace_mgr.get()) {
    ET_CHECK(trace_mgr.dump_to_file() == Error::Ok);
  }

  return 0;
}
