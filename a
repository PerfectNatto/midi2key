static Ort::Env ort(ORT_LOGGING_LEVEL_WARNING, "ort");

  // 2. SessionOptions に NNAPI EP を登録
  Ort::SessionOptions opts;
  Ort::ThrowOnError(OrtSessionOptionsAppendExecutionProvider_Nnapi(opts, 0)); // ← フラグ 0 でデフォルト設定

  // 3. セッション生成（パスは .c_str() で直接）
  Ort::Session session(ort, "model.onnx", opts);

  // 4. 入力テンソル作成（例：形状 {1,4}，float 4 要素）
  std::array<float, 4> input{1.f, 2.f, 3.f, 4.f};
  std::array<int64_t, 2> shape{1, 4};
  Ort::MemoryInfo mem = Ort::MemoryInfo::CreateCpu(OrtArenaAllocator, OrtMemTypeDefault);
  Ort::Value tensor = Ort::Value::CreateTensor<float>(mem, input.data(), input.size(),
                                                      shape.data(), shape.size());

  // 5. 推論実行
  const char* in_names[]  = {"input"};
  const char* out_names[] = {"output"};
  auto outs = session.Run(Ort::RunOptions{nullptr}, in_names, &tensor, 1, out_names, 1);

  // 6. 出力表示
  float* y = outs[0].GetTensorMutableData<float>();
  for (size_t i = 0; i < 4; ++i) std::printf("%f\n", y[i]);
